"""
Agente Editor de Fondo - Especializado en generaci√≥n de contenido acad√©mico sustantivo
"""
from typing import List, Dict, Any, Optional
from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage, AIMessage

from ..models.schemas import DocumentSection, ContentPiece, AgentRole, ContentType
from ..utils.rag_system import RAGSystem
from ..utils.document_processor import DocumentProcessor
from config import AGENT_CONFIG, OLLAMA_CONFIG, PATHS, VARIABLES_INDEPENDIENTES


class EditorFondoAgent:
    """
    Agente especializado en generaci√≥n de contenido acad√©mico sustantivo.
    Responsable de crear p√°rrafos conectados con variables independientes y fuentes.
    """

    def __init__(self, rag_system: RAGSystem):
        self.role = AgentRole.EDITOR_FONDO
        self.rag_system = rag_system
        self.document_processor = DocumentProcessor(PATHS["indice"], PATHS["reglas_apa"])
from config import AGENT_CONFIG, OLLAMA_CONFIG, VARIABLES_INDEPENDIENTES


class EditorFondoAgent:
    """
    Agente especializado en generaci√≥n de contenido acad√©mico sustantivo.
    Responsable de crear p√°rrafos conectados con variables independientes y fuentes.
    """

    def __init__(self, rag_system: RAGSystem, additional_context: str = ""):
        self.role = AgentRole.EDITOR_FONDO
        self.rag_system = rag_system
        self.document_processor = DocumentProcessor(PATHS["indice"], PATHS["reglas_apa"])
        self.additional_context = additional_context
        
        # Configurar LLM con Ollama
        self.llm = ChatOllama(
            model=OLLAMA_CONFIG["model"],
            base_url=OLLAMA_CONFIG["base_url"],
            temperature=AGENT_CONFIG["editor_fondo"]["temperature"],
            num_predict=AGENT_CONFIG["editor_fondo"]["max_tokens"]
        )

    def generate_section_content(self, section: DocumentSection, relevant_sources: List[ContentPiece], real_citations: List[Dict] = None) -> Dict[str, Any]:
        """
        Genera contenido acad√©mico sustantivo para una secci√≥n espec√≠fica.
        
        Args:
            section: Secci√≥n del documento a desarrollar
            relevant_sources: Fuentes relevantes encontradas por el investigador
            real_citations: Citas reales extra√≠das de los PDFs
            
        Returns:
            Dict con el contenido generado
        """
        if real_citations is None:
            real_citations = []
            
        # Preparar contexto de fuentes - USAR M√ÅS FUENTES PARA MAYOR VARIEDAD
        sources_context = "\n".join([
            f"Fuente {i+1}: {source.content[:500]}..." # M√°s contenido por fuente
            for i, source in enumerate(relevant_sources[:10])  # Usar hasta 10 fuentes
        ])
        
        # Preparar contexto de citas reales
        if real_citations:
            citations_context = "CITAS REALES AUTORIZADAS PARA USO:\n"
            for i, citation in enumerate(real_citations[:8]):  # M√°s citas disponibles
                citations_context += f"\n{i+1}. {citation['author']} ({citation['year']}). {citation['title']}. {citation.get('journal', '')} {citation.get('source', '')}"
            citations_context += "\n\n‚ö†Ô∏è USAR SOLO ESTAS CITAS - NO INVENTAR OTRAS"
        else:
            citations_context = "‚ö†Ô∏è NO HAY CITAS ESPEC√çFICAS DISPONIBLES - BASAR CONTENIDO EN LAS FUENTES SIN INVENTAR REFERENCIAS"
        
        # Identificar variables independientes relevantes
        relevant_variables = [var for var in VARIABLES_INDEPENDIENTES 
                            if any(keyword in section.title.lower() 
                                  for keyword in var.lower().split())]
        
        prompt = f"""
{self.additional_context}

Como editor acad√©mico especializado, desarrolla contenido acad√©mico profundo y comprehensivo para la siguiente secci√≥n del marco te√≥rico:

**SECCI√ìN:** {section.title}
**NIVEL:** {section.level}
**VARIABLES INDEPENDIENTES RELEVANTES:** {', '.join(relevant_variables)}

**FUENTES DISPONIBLES:**
{sources_context}

**CITAS REALES DISPONIBLES (USAR ESTAS EN LUGAR DE CITAS FICTICIAS):**
{citations_context}

üö® **REGLAS CR√çTICAS SOBRE CITAS - CUMPLIMIENTO OBLIGATORIO** üö®

‚ùå **CITAS TOTALMENTE PROHIBIDAS (BLOQUEAR INMEDIATAMENTE):**
- Maslach & Jackson (1981) - PROHIBIDA
- Maslach, C., & Jackson, S. E. (1981) - PROHIBIDA 
- Demerouti & Bakker (2017) - PROHIBIDA
- OMS (2019) - PROHIBIDA
- WHO (2019) - PROHIBIDA
- Burnout Research Consortium - PROHIBIDA
- American Psychological Association - PROHIBIDA
- World Health Organization - PROHIBIDA
- Cualquier variaci√≥n de Maslach - PROHIBIDA
- Cualquier cita acad√©mica que no est√© expl√≠citamente autorizada - PROHIBIDA

‚ö†Ô∏è **CONSECUENCIA DE USAR CITAS PROHIBIDAS**: El contenido ser√° RECHAZADO

‚úÖ **√öNICAS CITAS AUTORIZADAS (VERIFICAR LISTA):**
{citations_context}

ÔøΩ **VERIFICACI√ìN OBLIGATORIA ANTES DE CUALQUIER CITA:**
1. ¬øAparece EXACTAMENTE en la lista de citas autorizadas? ‚Üí SI: Proceder. NO: ELIMINAR
2. ¬øEs similar a una cita prohibida? ‚Üí ELIMINAR inmediatamente
3. ¬øParece acad√©micamente v√°lida pero no est√° autorizada? ‚Üí ELIMINAR

üéØ **SI NO HAY CITAS AUTORIZADAS**: Escribir contenido descriptivo SIN CITAS en lugar de inventar

üéØ **ENFOQUE TEM√ÅTICO ESPEC√çFICO**: 
- El contenido DEBE centrarse √öNICAMENTE en el tema espec√≠fico de la secci√≥n: "{section.title}"
- NO generar contenido gen√©rico sobre burnout acad√©mico
- NO usar numeraci√≥n incorrecta (como 2.1.x cuando deber√≠a ser sobre el tema espec√≠fico)
- Desarrollar ESPEC√çFICAMENTE el aspecto mencionado en el t√≠tulo de la secci√≥n

**INSTRUCCIONES ESPEC√çFICAS - CONTENIDO EXTENSO Y PROFUNDO:**
1. Genera contenido acad√©mico EXTENSO y DETALLADO de nivel universitario avanzado
2. M√çNIMO 800-1200 palabras por secci√≥n principal, 500-700 palabras por subsecci√≥n
3. Usa TODAS las fuentes disponibles, no solo las primeras
4. Incluye m√∫ltiples perspectivas te√≥ricas y enfoques metodol√≥gicos
5. Desarrolla argumentos complejos con an√°lisis cr√≠tico profundo
6. NO repitas el t√≠tulo de la secci√≥n (viene autom√°ticamente del sistema)

**ESTRUCTURA EXTENSIVA REQUERIDA:**
1. **Introducci√≥n conceptual** (2-3 p√°rrafos, 200-300 palabras total)
2. **Desarrollo te√≥rico principal** (4-5 p√°rrafos, 200-250 palabras cada uno)
3. **An√°lisis metodol√≥gico y evidencia emp√≠rica** (2-3 p√°rrafos, 150-200 palabras cada uno)
4. **Perspectivas comparativas y debates actuales** (2 p√°rrafos, 150-200 palabras cada uno)
5. **Tabla comparativa compleja** (1 tabla detallada + 1 p√°rrafo explicativo 150 palabras)
6. **Conexiones con variables independientes** (2 p√°rrafos, 150-200 palabras cada uno)
7. **Implicaciones te√≥ricas y pr√°cticas** (1 p√°rrafo, 150-200 palabras)
8. **Referencias** (al final, una sola vez, SOLO las citas reales utilizadas)

**FORMATO DE RESPUESTA EXTENSO (ESTRUCTURA FIJA - NO INCLUIR T√çTULO DE SECCI√ìN):**

[P√°rrafo 1: Introducci√≥n conceptual - contexto te√≥rico y definiciones fundamentales - 150 palabras]

[P√°rrafo 2: Marco conceptual complementario - perspectivas adicionales y enfoques disciplinarios - 150 palabras]

**Desarrollo te√≥rico principal**

[P√°rrafo 1: Primera perspectiva te√≥rica principal - 250 palabras con an√°lisis profundo]

[P√°rrafo 2: Segunda perspectiva te√≥rica - enfoques complementarios y contrastantes - 250 palabras]

[P√°rrafo 3: Tercera perspectiva - s√≠ntesis e integraci√≥n te√≥rica - 200 palabras]

[P√°rrafo 4: Evidencia emp√≠rica contempor√°nea - estudios recientes y hallazgos - 200 palabras]

**An√°lisis metodol√≥gico y evidencia emp√≠rica**

[P√°rrafo 1: Metodolog√≠as de investigaci√≥n - enfoques cuantitativos y cualitativos - 180 palabras]

[P√°rrafo 2: Hallazgos emp√≠ricos clave - resultados de investigaci√≥n y tendencias - 180 palabras]

**Perspectivas comparativas y debates actuales**

[P√°rrafo 1: Debates te√≥ricos contempor√°neos - controversias y discusiones acad√©micas - 180 palabras]

[P√°rrafo 2: Comparaci√≥n de enfoques - ventajas y limitaciones de diferentes perspectivas - 180 palabras]

**Tabla [N√∫mero]: [T√≠tulo descriptivo y espec√≠fico]**
| Aspecto | Perspectiva A | Perspectiva B | Perspectiva C | Implicaciones |
|---------|---------------|---------------|---------------|---------------|
| [Elemento 1] | [Descripci√≥n detallada] | [Descripci√≥n contrastante] | [Enfoque alternativo] | [Implicaciones te√≥ricas] |
| [Elemento 2] | [Descripci√≥n detallada] | [Descripci√≥n contrastante] | [Enfoque alternativo] | [Implicaciones pr√°cticas] |
| [Elemento 3] | [Descripci√≥n detallada] | [Descripci√≥n contrastante] | [Enfoque alternativo] | [Implicaciones metodol√≥gicas] |
| [Elemento 4] | [Descripci√≥n detallada] | [Descripci√≥n contrastante] | [Enfoque alternativo] | [Implicaciones futuras] |

[P√°rrafo explicativo de la tabla - an√°lisis comparativo detallado - 150 palabras]

**Conexiones con variables independientes**

[P√°rrafo 1: Primera conexi√≥n - relaci√≥n con variables espec√≠ficas - 180 palabras]

[P√°rrafo 2: Segunda conexi√≥n - interacciones complejas y mediadores - 180 palabras]

**Implicaciones te√≥ricas y pr√°cticas**

[P√°rrafo s√≠ntesis - implicaciones para la teor√≠a, investigaci√≥n y pr√°ctica - 180 palabras]

[P√°rrafo explicativo de la tabla]

**Conexiones con variables independientes**

[P√°rrafo conectando espec√≠ficamente con las variables de burnout acad√©mico]

**Referencias**

[Lista SOLO de las citas reales utilizadas del listado proporcionado - NO inventar ninguna nueva]

‚ö†Ô∏è CR√çTICO: El t√≠tulo de secci√≥n (## 2.1.1 Definici√≥n...) se agrega autom√°ticamente - NO lo incluyas en tu respuesta.

[P√°rrafo introductorio con definiciones b√°sicas]

[P√°rrafo de desarrollo conceptual principal]

### Tabla [N√∫mero]: [T√≠tulo descriptivo]
| Aspecto | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| [Fila 1] | [Descripci√≥n] | [Ejemplo] |
| [Fila 2] | [Descripci√≥n] | [Ejemplo] |
| [Fila 3] | [Descripci√≥n] | [Ejemplo] |

[P√°rrafo conectando con variables independientes]

### Figura [N√∫mero]: [T√≠tulo sugerido]
**Descripci√≥n:** [Descripci√≥n de figura/diagrama sugerido]
**Elementos:** [Lista de elementos que deber√≠a contener]

[P√°rrafo de s√≠ntesis y transici√≥n]

Aseg√∫rate de que cada p√°rrafo tenga al menos una cita y que las tablas sean informativas y relevantes.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            # Aplanar las listas de fuentes
            all_sources = []
            for source in relevant_sources:
                all_sources.extend(source.sources)
            
            return {
                "section_id": section.id,
                "section_title": section.title,
                "generated_content": response.content,
                "variables_addressed": relevant_variables,
                "sources_used": all_sources,
                "word_count": len(response.content.split()),
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "section_id": section.id,
                "section_title": section.title,
                "generated_content": f"Error en la generaci√≥n: {str(e)}",
                "variables_addressed": relevant_variables,
                "sources_used": [],
                "word_count": 0,
                "status": "error",
                "agent_role": self.role.value
            }

    def enhance_paragraph(self, paragraph: str, variable_focus: str, additional_sources: List[str] = None) -> Dict[str, Any]:
        """
        Mejora un p√°rrafo existente enfoc√°ndose en una variable independiente espec√≠fica.
        
        Args:
            paragraph: P√°rrafo a mejorar
            variable_focus: Variable independiente a enfatizar
            additional_sources: Fuentes adicionales opcionales
            
        Returns:
            Dict con el p√°rrafo mejorado
        """
        sources_text = ""
        if additional_sources:
            sources_text = f"\n**FUENTES ADICIONALES:**\n" + "\n".join(additional_sources)

        prompt = f"""
Como editor acad√©mico, mejora el siguiente p√°rrafo enfoc√°ndote espec√≠ficamente en la variable independiente indicada:

**P√ÅRRAFO ORIGINAL:**
{paragraph}

**VARIABLE INDEPENDIENTE A ENFATIZAR:** {variable_focus}
{sources_text}

**MEJORAS REQUERIDAS:**
1. Ampl√≠a la conexi√≥n con la variable independiente especificada
2. Agrega detalles conceptuales relevantes
3. Incluye ejemplos o aplicaciones espec√≠ficas
4. Mejora la fluidez y coherencia
5. Mant√©n el rigor acad√©mico
6. Conserva o mejora las citas existentes

**RESULTADO:** Devuelve el p√°rrafo mejorado manteniendo la estructura acad√©mica formal.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                "original_paragraph": paragraph[:200] + "..." if len(paragraph) > 200 else paragraph,
                "enhanced_paragraph": response.content,
                "variable_focus": variable_focus,
                "improvement_applied": True,
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "original_paragraph": paragraph[:200] + "..." if len(paragraph) > 200 else paragraph,
                "enhanced_paragraph": f"Error en la mejora: {str(e)}",
                "variable_focus": variable_focus,
                "improvement_applied": False,
                "status": "error",
                "agent_role": self.role.value
            }

    def create_transition_paragraph(self, current_section: str, next_section: str) -> Dict[str, Any]:
        """
        Crea un p√°rrafo de transici√≥n entre secciones.
        
        Args:
            current_section: Secci√≥n actual
            next_section: Siguiente secci√≥n
            
        Returns:
            Dict con el p√°rrafo de transici√≥n
        """
        prompt = f"""
Como editor acad√©mico, crea un p√°rrafo de transici√≥n fluido y acad√©mico entre las siguientes secciones:

**SECCI√ìN ACTUAL:** {current_section}
**SIGUIENTE SECCI√ìN:** {next_section}

**CARACTER√çSTICAS DEL P√ÅRRAFO:**
1. 40-60 palabras m√°ximo
2. Conecta l√≥gicamente ambas secciones
3. Mantiene el hilo argumentativo
4. Usa conectores acad√©micos apropiados
5. Prepara al lector para el cambio de tema

**FORMATO:** Un solo p√°rrafo sin citas, enfocado en la transici√≥n conceptual.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                "from_section": current_section,
                "to_section": next_section,
                "transition_paragraph": response.content,
                "word_count": len(response.content.split()),
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "from_section": current_section,
                "to_section": next_section,
                "transition_paragraph": f"Error en la transici√≥n: {str(e)}",
                "word_count": 0,
                "status": "error",
                "agent_role": self.role.value
            }

    def synthesize_concepts(self, concepts: List[str], target_variable: str) -> Dict[str, Any]:
        """
        Sintetiza m√∫ltiples conceptos relacionados con una variable independiente.
        
        Args:
            concepts: Lista de conceptos a sintetizar
            target_variable: Variable independiente objetivo
            
        Returns:
            Dict con la s√≠ntesis conceptual
        """
        concepts_text = "\n".join([f"- {concept}" for concept in concepts])
        
        prompt = f"""
Como editor acad√©mico especializado, sintetiza los siguientes conceptos en relaci√≥n con la variable independiente especificada:

**VARIABLE INDEPENDIENTE:** {target_variable}

**CONCEPTOS A SINTETIZAR:**
{concepts_text}

**INSTRUCCIONES:**
1. Identifica las relaciones entre los conceptos
2. Construye un marco conceptual coherente
3. Conecta todos los conceptos con la variable independiente
4. Crea una s√≠ntesis de 150-200 palabras
5. Usa lenguaje acad√©mico preciso
6. Estructura la s√≠ntesis l√≥gicamente

**FORMATO:** Un p√°rrafo sint√©tico que integre todos los conceptos de manera coherente.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                "target_variable": target_variable,
                "concepts_synthesized": concepts,
                "synthesis": response.content,
                "concepts_count": len(concepts),
                "word_count": len(response.content.split()),
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "target_variable": target_variable,
                "concepts_synthesized": concepts,
                "synthesis": f"Error en la s√≠ntesis: {str(e)}",
                "concepts_count": len(concepts),
                "word_count": 0,
                "status": "error",
                "agent_role": self.role.value
            }

    def generate_content_piece(self, section_id: str, content_type: ContentType, requirements: Dict[str, Any]) -> ContentPiece:
        """
        Genera una pieza de contenido espec√≠fica seg√∫n los requerimientos.
        
        Args:
            section_id: ID de la secci√≥n
            content_type: Tipo de contenido a generar
            requirements: Requerimientos espec√≠ficos
            
        Returns:
            ContentPiece: Pieza de contenido generada
        """
        try:
            if content_type == ContentType.PARAGRAPH:
                content = self.generate_section_content(
                    requirements.get("section"), 
                    requirements.get("sources", [])
                )
                generated_text = content["generated_content"]
                sources = content["sources_used"]
                variables = content["variables_addressed"]
                
            else:
                generated_text = f"Contenido de tipo {content_type.value} generado"
                sources = []
                variables = []
            
            content_piece = ContentPiece(
                id=f"editor_fondo_{section_id}_{content_type.value}",
                section_id=section_id,
                content_type=content_type,
                content=generated_text,
                sources=sources,
                variables_independientes=variables,
                created_by=self.role,
                quality_score=0.85  # Score base para contenido generado
            )
            
            return content_piece
            
        except Exception as e:
            # Crear contenido de error
            error_content = ContentPiece(
                id=f"editor_fondo_error_{section_id}",
                section_id=section_id,
                content_type=ContentType.PARAGRAPH,
                content=f"Error generando contenido: {str(e)}",
                sources=[],
                variables_independientes=[],
                created_by=self.role,
                quality_score=0.0
            )
            return error_content

    def generate_content_table(self, topic: str, relevant_sources: List[ContentPiece]) -> Dict[str, Any]:
        """
        Genera una tabla acad√©mica espec√≠fica para un tema.
        
        Args:
            topic: Tema para la tabla
            relevant_sources: Fuentes relevantes
            
        Returns:
            Dict con la tabla generada
        """
        sources_context = "\n".join([
            f"Fuente {i+1}: {source.content[:200]}..."
            for i, source in enumerate(relevant_sources[:3])
        ])
        
        prompt = f"""
Como editor acad√©mico, crea una tabla informativa y bien estructurada sobre el siguiente tema:

**TEMA:** {topic}

**FUENTES DISPONIBLES:**
{sources_context}

**INSTRUCCIONES:**
1. Crea una tabla de 4-6 filas con 3-4 columnas
2. Incluye encabezados descriptivos y claros
3. Aseg√∫rate de que la informaci√≥n sea precisa y relevante
4. Basate en las fuentes proporcionadas cuando sea posible
5. Usa formato Markdown para la tabla

**TIPOS DE TABLA SUGERIDOS:**
- Tabla comparativa (caracter√≠sticas vs. enfoques)
- Tabla de clasificaci√≥n (categor√≠as y ejemplos)
- Tabla de ventajas/desventajas
- Tabla de procesos (pasos y descripciones)

**FORMATO DE RESPUESTA:**
### Tabla: [T√≠tulo descriptivo]

| [Columna 1] | [Columna 2] | [Columna 3] | [Columna 4] |
|-------------|-------------|-------------|-------------|
| [Dato 1] | [Dato 2] | [Dato 3] | [Dato 4] |
| [Dato 1] | [Dato 2] | [Dato 3] | [Dato 4] |
| [Dato 1] | [Dato 2] | [Dato 3] | [Dato 4] |

**Fuente:** Elaboraci√≥n propia basada en [citar fuentes]

Genera una tabla √∫til e informativa que enriquezca el contenido acad√©mico.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                "topic": topic,
                "table_content": response.content,
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "topic": topic,
                "table_content": f"Error generando tabla: {str(e)}",
                "status": "error",
                "agent_role": self.role.value
            }

    def suggest_figure(self, topic: str, context: str) -> Dict[str, Any]:
        """
        Sugiere una figura o diagrama para enriquecer el contenido.
        
        Args:
            topic: Tema para la figura
            context: Contexto del contenido
            
        Returns:
            Dict con la sugerencia de figura
        """
        prompt = f"""
Como editor acad√©mico especializado, sugiere una figura o diagrama que enriquezca el siguiente contenido:

**TEMA:** {topic}
**CONTEXTO:** {context}

**INSTRUCCIONES:**
1. Sugiere un tipo de figura apropiado (diagrama, esquema, gr√°fico, etc.)
2. Proporciona un t√≠tulo descriptivo
3. Lista los elementos principales que debe contener
4. Explica c√≥mo contribuir√≠a al entendimiento del tema
5. Sugiere la posici√≥n √≥ptima en el texto

**TIPOS DE FIGURA SUGERIDOS:**
- Diagrama de flujo (para procesos)
- Esquema conceptual (para relaciones)
- Gr√°fico comparativo (para datos)
- Modelo te√≥rico (para frameworks)
- Timeline (para evoluci√≥n temporal)

**FORMATO DE RESPUESTA:**
### Figura [N√∫mero]: [T√≠tulo descriptivo]

**Tipo:** [Tipo de figura]
**Descripci√≥n:** [Descripci√≥n detallada de qu√© mostrar√≠a]
**Elementos principales:**
- [Elemento 1]
- [Elemento 2]
- [Elemento 3]

**Contribuci√≥n:** [C√≥mo ayudar√≠a al entendimiento]
**Posici√≥n sugerida:** [D√≥nde ubicarla en el texto]

Proporciona una sugerencia √∫til y espec√≠fica.
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                "topic": topic,
                "figure_suggestion": response.content,
                "status": "completed",
                "agent_role": self.role.value
            }
            
        except Exception as e:
            return {
                "topic": topic,
                "figure_suggestion": f"Error sugiriendo figura: {str(e)}",
                "status": "error",
                "agent_role": self.role.value
            }

    def generate_comprehensive_content(self, section, fuentes_disponibles, variables_independientes, modo="principal"):
        """
        Genera contenido acad√©mico extenso y detallado en diferentes modos.
        
        Args:
            section: Secci√≥n del documento
            fuentes_disponibles: Lista de fuentes disponibles
            variables_independientes: Variables del estudio
            modo: Tipo de contenido ("principal", "comparativo", "variables")
            
        Returns:
            Dict con contenido generado extenso
        """
        if modo == "principal":
            return self._generate_principal_content(section, fuentes_disponibles, variables_independientes)
        elif modo == "comparativo":
            return self._generate_comparative_content(section, fuentes_disponibles, variables_independientes)
        elif modo == "variables":
            return self._generate_variables_content(section, fuentes_disponibles, variables_independientes)
        else:
            return self.generate_section_content(section, fuentes_disponibles)

    def _generate_principal_content(self, section, fuentes_disponibles, variables_independientes):
        """Genera contenido principal extenso y detallado"""
        
        sources_context = "\n".join([
            f"Fuente {i+1}: {source.content[:400]}..."
            for i, source in enumerate(fuentes_disponibles[:8])  # M√°s fuentes
        ])
        
        prompt = f"""
Como editor acad√©mico especializado, desarrolla contenido PRINCIPAL extenso y detallado para:

**SECCI√ìN:** {section.title}
**VARIABLES INDEPENDIENTES:** {', '.join(variables_independientes)}

**FUENTES DISPONIBLES:**
{sources_context}

**INSTRUCCIONES PARA CONTENIDO PRINCIPAL (1200-1500 palabras):**
1. Introducci√≥n conceptual completa con definiciones m√∫ltiples
2. Desarrollo hist√≥rico del concepto
3. Teor√≠as fundamentales y enfoques principales
4. Estado actual de la investigaci√≥n
5. Debates y controversias actuales
6. M√∫ltiples perspectivas disciplinarias

**ESTRUCTURA OBLIGATORIA:**
- P√°rrafo introductorio (100-150 palabras)
- 4-5 p√°rrafos de desarrollo te√≥rico (150-200 palabras cada uno)
- 2-3 p√°rrafos de an√°lisis cr√≠tico
- P√°rrafo de s√≠ntesis
- M√≠nimo 8 citas acad√©micas diferentes
- Al menos una tabla clasificatoria

GENERA CONTENIDO ACAD√âMICO PRINCIPAL EXTENSO Y DETALLADO:
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return {
                "tipo": "principal",
                "contenido": response.content,
                "palabras": len(response.content.split()),
                "status": "completed"
            }
        except Exception as e:
            return {"tipo": "principal", "contenido": f"Error: {e}", "status": "error"}

    def _generate_comparative_content(self, section, fuentes_disponibles, variables_independientes):
        """Genera contenido comparativo y an√°lisis cr√≠tico"""
        
        prompt = f"""
Como editor acad√©mico, desarrolla AN√ÅLISIS COMPARATIVO extenso para:

**SECCI√ìN:** {section.title}
**VARIABLES:** {', '.join(variables_independientes)}

**INSTRUCCIONES PARA AN√ÅLISIS COMPARATIVO (800-1000 palabras):**
1. Comparaci√≥n entre diferentes enfoques te√≥ricos
2. An√°lisis de ventajas y limitaciones
3. Contrastes metodol√≥gicos
4. Debates contempor√°neos
5. S√≠ntesis integradora

**ELEMENTOS OBLIGATORIOS:**
- Tabla comparativa de enfoques/teor√≠as
- An√°lisis de pros y contras
- Identificaci√≥n de gaps de investigaci√≥n
- Recomendaciones metodol√≥gicas

GENERA AN√ÅLISIS COMPARATIVO DETALLADO:
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return {
                "tipo": "comparativo",
                "contenido": response.content,
                "palabras": len(response.content.split()),
                "status": "completed"
            }
        except Exception as e:
            return {"tipo": "comparativo", "contenido": f"Error: {e}", "status": "error"}

    def _generate_variables_content(self, section, fuentes_disponibles, variables_independientes):
        """Genera contenido espec√≠fico sobre variables independientes"""
        
        prompt = f"""
Como editor acad√©mico, desarrolla contenido espec√≠fico sobre VARIABLES INDEPENDIENTES para:

**SECCI√ìN:** {section.title}
**VARIABLES INDEPENDIENTES:** {', '.join(variables_independientes)}

**INSTRUCCIONES PARA CONTENIDO DE VARIABLES (600-800 palabras):**
1. Definici√≥n operacional de cada variable
2. Instrumentos de medici√≥n validados
3. Relaciones entre variables
4. Evidencia emp√≠rica disponible
5. Modelos te√≥ricos que las incorporan

**ELEMENTOS OBLIGATORIOS:**
- Tabla de variables y definiciones operacionales
- Descripci√≥n de instrumentos de medici√≥n
- An√°lisis de relaciones causales
- Evidencia emp√≠rica reciente

GENERA CONTENIDO ESPEC√çFICO SOBRE VARIABLES:
"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return {
                "tipo": "variables",
                "contenido": response.content,
                "palabras": len(response.content.split()),
                "status": "completed"
            }
        except Exception as e:
            return {"tipo": "variables", "contenido": f"Error: {e}", "status": "error"}

    def get_agent_status(self):
        """
        Obtiene el estado actual del agente editor de fondo.
        
        Returns:
            Dict con informaci√≥n del estado del agente
        """
        return {
            "role": self.role.value,
            "model": OLLAMA_CONFIG["model"],
            "temperature": AGENT_CONFIG["editor_fondo"]["temperature"],
            "max_tokens": AGENT_CONFIG["editor_fondo"]["max_tokens"],
            "rag_initialized": self.rag_system is not None,
            "capabilities": [
                "generate_section_content",
                "enhance_paragraph",
                "create_transition_paragraph",
                "synthesize_concepts",
                "generate_content_piece",
                "generate_comprehensive_content"
            ],
            "variables_independientes": VARIABLES_INDEPENDIENTES
        }

    def __str__(self) -> str:
        return f"EditorFondoAgent(role={self.role.value}, model={OLLAMA_CONFIG['model']})"

    def __repr__(self) -> str:
        return self.__str__()
